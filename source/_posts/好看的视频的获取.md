---
title: 好看的视频的获取
date: 2021-07-01 22:00:03
categories: 
- 技术
- python
cover: /img/cover5.png
---

　　在网上找到了好康的视频，却苦于不能下载？让我试试。

## 原理分析

　　首先，打开要下载的视频的网页链接，（这里不知道为什么，`F12`找不到，`Ctrl` + `U`能找到）可以看到一串这样的JSON代码（没错，又是json）

```json
    window.__PRELOADED_STATE__ = {
            //……
            "clarityUrl":[
                //……
                url":"……"
                //……
            ]
        }
```

　　而且，在clarityUrl数组里面，序号最大的往往是最高清的，作为对视频画质要求**极高**的我来说，当然需要下载最大的啦！
当然也可以向上一篇K歌一样，通过控制台的方式快速获得。

```js
window.__PRELOADED_STATE__.curVideoMeta.clarityUrl[3].url
```

　　上面的数字3可以换成其他的数字，根据清晰度数目来确定。但是！一个个下载也太麻烦了……所以我决定写一个脚本，自己爬！~~不是我爬，是程序爬。~~

## 开始！
1. 库？
　　一开始准备打包成一个`exe`小程序，却用了`pandas`这样庞大的库，不仅大，而且各种报错，后来还是用回了以前喜欢的`csv`库，果然大大缩小了程序，才6M多，真香。
看看用了哪些库？
```python
from re import findall#正则表达式
from requests import get#经典get了
import json#json
from pyperclip import copy#懒得复制
import csv#读写csv
```
　　`json`和`csv`我觉得应该可能也许大概够小了，所以就懒得写`from——import——`了。但是要用`pyinstaller`打包程序最好写成这种形式，否则会很大的！
p.s.:发现貌似原来用了pyperclip，后来加上了下载功能，pyperclip导入了没用上哇。

2. 开始读写csv！
　　话不多说，先上代码。
```python
def getUrls(filename):
    data_list = []
    with open(filename, newline='') as csvfile:
        data = csv.reader(csvfile, delimiter=',', quotechar='|')
        for i in data:
            data_list.append(i)
    for i in data_list:
        i.extend(getHaokan(i[0]))
    with open(filename, 'w', newline='') as csvfile:
        spamwriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)
        for i in data_list:
            spamwriter.writerow(i)
    return data_list
```
　　自pandas巨大之后火速改的，可能不太好，~~以后有空再改吧~~`下次一定`！

　　要注意的是，csv格式要求是必须只有一列，而且每行只有一个网址，另外，要加协议名http(s)，不然可能会报错。可以参考一下我的测试文件：
```csv
https://haokan.baidu.com/v?vid=18259362659725323076	
https://haokan.baidu.com/v?vid=12158529895360920683&tab=recommend
```
3. 接下来是给爷爬
```python
def getHaokan(url):
    res = get(url)
    text = res.text
    regex = findall("window.__PRELOADED_STATE__\s=\s(.*?);[\s]*document",text)
    jsonobj = json.loads(regex[0])
    title = findall("\<title>(.*?)\<\/title>",text)[0]
    return jsonobj['curVideoMeta']['clarityUrl'][-1]['url'],title
```
　　用的是正则匹配，匹配网址和标题。
4. 到了激动人心的下载环节
```python
def downLoad(data_list):
    for i in data_list:
        mp4file=open(i[2]+'.mp4','wb')
        print("Downloading \t---",i[2],"--- ...")
        for chunk in get(i[1]).iter_content(100000):
            mp4file.write(chunk)
        mp4file.close()
```
　　具体代码请自行参阅[github](https://github.com/Williamrjw/FantasticTools)仓库，欢迎提出![Bitbucket open issues](https://img.shields.io/bitbucket/issues-raw/Williamrjw/FantasticTools?style=social)  

tips：

- 下载前建议备份一个csv文件，否则可能导致下载没下好，还把辛苦复制上去的网址弄丢了的尴尬局面。（比如网址错了，爆出个错误来）
- 发现title出现通配符*等不能作为文件名的特殊符号时，会报错，因此，需要改进……`下次一定`！
- 下次打包记得把pyperclip库删了。

欢迎直接下载[exe](https://williamrjw.vercel.app/pan/haokan.exe)文件运行~